{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1lczKhDl5qBUZlwrivOXpES-sp3i8CRYK","timestamp":1687799499485}],"authorship_tag":"ABX9TyOqjFtuYYC0qDtmH0UiYjSn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"ZgJfMLPFitTf","executionInfo":{"status":"ok","timestamp":1687883959675,"user_tz":420,"elapsed":5860,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"outputs":[],"source":["#import\n","\n","import torch\n","import torch.nn as nn # nn stuff\n","import torch.optim as optim # optimizer\n","import torch.nn.functional as f # no param functions exp, tanh vs keras functional\n","from torch.utils.data import DataLoader # utilities in data field\n","import torchvision.datasets as datasets # with tfds\n","import torchvision.transforms as transforms"]},{"cell_type":"code","source":["#set device\n","#conditional with .cuda.is_avaiable\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"QQa4uArli3-N","executionInfo":{"status":"ok","timestamp":1687883959675,"user_tz":420,"elapsed":7,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#hyperparam\n","input_size = 28\n","num_classes = 10\n","learning_rate = 0.001\n","batch_size = 64\n","num_epochs = 1"],"metadata":{"id":"RGOcj1IPi5gr","executionInfo":{"status":"ok","timestamp":1687883959676,"user_tz":420,"elapsed":7,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#create\n","class CNN(nn.Module):\n","  def __init__(self,in_channels=1, num_classes=10):\n","    super(CNN, self).__init__()\n","    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), padding=(1,1), stride=(1,1))\n","    self.pool = nn.MaxPool2d(stride=(2,2), kernel_size=(2,2))\n","    self.conv2 = nn.Conv2d(in_channels =8, out_channels=16, kernel_size=(3,3), padding=(1,1), stride=(1,1))\n","    self.fc1 = nn.Linear(16*7*7, num_classes) # 7*7 28 * 28 pooled twice\n","  def forward(self, x):\n","    x = f.relu(self.conv1(x))\n","    x = self.pool(x)\n","    x = f.relu(self.conv2(x))\n","    x = self.pool(x)\n","    x = x.reshape(x.shape[0], -1)\n","    x = self.fc1(x)\n","    return x\n","\n","model = CNN()\n","x = torch.randn(64, 1, 28, 28)\n","print(model(x).shape) # test out model (really just matrix mult so has shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnyufMW_i3LC","executionInfo":{"status":"ok","timestamp":1687883960089,"user_tz":420,"elapsed":419,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}},"outputId":"18aa44be-b328-4c6a-dc38-3bb24edb8495"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}]},{"cell_type":"code","source":["#load data\n","train_dataset = datasets.MNIST(root='dataset/', train=True,\n","                               transform = transforms.ToTensor(),\n","                               download=True) # create folder , get train, download if not there\n","train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n","# batch - for batch in train_loader\n","#usually for i, batch in enumerate(train_loader, start=1) for index\n","# test on my own\n","test_dataset = datasets.MNIST(root='dataset/', train=False,\n","                              transform=transforms.ToTensor(),\n","                              download=True)\n","test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)\n"],"metadata":{"id":"NvReGvabi6eq","executionInfo":{"status":"ok","timestamp":1687883960794,"user_tz":420,"elapsed":711,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a0ce3b39-70a7-4610-985a-408704e4752f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 367218209.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 27606128.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 96136831.67it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 4542/4542 [00:00<00:00, 13312738.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","\n"]}]},{"cell_type":"code","source":["#init\n","#tensor .to() -> device\n","model = CNN(num_classes=num_classes).to(device)"],"metadata":{"id":"hfjEMAxLi7-z","executionInfo":{"status":"ok","timestamp":1687883960794,"user_tz":420,"elapsed":3,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#loss and opt\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate) # learning rate\n","# Adam on model params"],"metadata":{"id":"Wn0UZ1e0i9vE","executionInfo":{"status":"ok","timestamp":1687883960795,"user_tz":420,"elapsed":4,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#train\n","for epoch in range(num_epochs):\n","  for batch_ids, (data, targets) in enumerate(train_loader):\n","    # get data to cuda if pos\n","    data = data.to(device=device)\n","    targets = targets.to(device=device)\n","\n","    #print(data.shape) #64, 1 for color, 28x28\n","    #set correct shape\n","    #data = data.reshape(data.shape[0], -1)\n","\n","    scores = model(data)\n","    loss = criterion(scores, targets)\n","\n","    optimizer.zero_grad() # rezero\n","    loss.backward() # get losses # tf.backward similar\n","\n","    optimizer.step() # steps through grad\n","\n","\n"],"metadata":{"id":"xFMKyncii-wR","executionInfo":{"status":"ok","timestamp":1687883983763,"user_tz":420,"elapsed":22971,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#eval#\n","def check_accuracy(loader, model):\n","  if loader.dataset.train: # check if train bool\n","    print(\"Checking accuracy on training data\")\n","  else:\n","    print(\"Checking accuracy on test data\")\n","  num_correct = 0\n","  num_samples = 0\n","  model.eval()\n","  with torch.no_grad(): # no any grads here\n","    for x, y in loader:\n","      x = x.to(device=device)\n","      y = y.to(device=device)\n","      #x = x.reshape(x.shape[0], -1)\n","\n","      scores = model(x)\n","      _, predictions = scores.max(1) # get high prob, gives index\n","      num_correct += (predictions == y).sum() # where indexes are correct\n","      num_samples += predictions.size(0)  # for batch\n","  print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples) * 100:.2f}')\n","  model.train()\n","check_accuracy(train_loader, model)\n","check_accuracy(test_loader, model)"],"metadata":{"id":"44CACFmBjAVp","executionInfo":{"status":"ok","timestamp":1687884001891,"user_tz":420,"elapsed":18130,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a39b55d-62b8-40e8-bff5-9286a1213673"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Checking accuracy on training data\n","Got 57760 / 60000 with accuracy 96.27\n","Checking accuracy on test data\n","Got 9659 / 10000 with accuracy 96.59\n"]}]},{"cell_type":"code","source":["# CIFAR so far 100 of these set the bar.\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as f\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as datasets\n","from torchvision.transforms import ToTensor\n"],"metadata":{"id":"67nSk8BexXix","executionInfo":{"status":"ok","timestamp":1687884002058,"user_tz":420,"elapsed":180,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"edu6q8KYzjhQ","executionInfo":{"status":"ok","timestamp":1687884002058,"user_tz":420,"elapsed":5,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#hyp\n","input_size = 32\n","batch_size = 32\n","num_epochs = 5\n","num_classes = 100\n","lr = 0.001"],"metadata":{"id":"kAlPjgadzkv0","executionInfo":{"status":"ok","timestamp":1687884699958,"user_tz":420,"elapsed":224,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["my_channels_indices = [3, 8, 16, 32]\n","class CifarCNN(nn.Module):\n","  def __init__(self, num_classes=100):\n","    super(CifarCNN, self).__init__()\n","    self.conv_layers = [nn.Conv2d(in_channels = my_channels_indices[i], out_channels=my_channels_indices[i+1], kernel_size = (3,3), stride = (1,1), padding=(1,1)) for i in range(len(my_channels_indices) -1)]\n","    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n","    self.output = nn.Linear(my_channels_indices[len(my_channels_indices) - 1] * 4*4, num_classes)\n","  def forward(self, x):\n","    for i in range(len(self.conv_layers)):\n","      x = self.conv_layers[i](x)\n","      x = self.pool(x)\n","    x = x.reshape(x.shape[0],-1)\n","    return self.output(x)\n","model = CifarCNN()\n","rand_input = torch.randn(32,3, 32, 32)\n","model(rand_input)\n"],"metadata":{"id":"AZVrPBJYyIFX","executionInfo":{"status":"ok","timestamp":1687885531516,"user_tz":420,"elapsed":216,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f608b54c-7925-41f8-eda0-4e9377becd8b"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.1737e-01,  1.4335e-01, -1.1466e-01,  ...,  2.0476e-02,\n","          3.4558e-02, -6.5831e-02],\n","        [-3.1231e-02,  1.5097e-01, -9.6956e-02,  ...,  7.0900e-02,\n","          6.6000e-02, -8.5661e-02],\n","        [-1.1928e-01,  9.6439e-02, -1.3558e-01,  ..., -4.1118e-02,\n","          8.9791e-02, -8.9281e-02],\n","        ...,\n","        [-3.0985e-02,  9.9687e-02, -6.9807e-02,  ..., -4.7876e-02,\n","          4.2326e-02, -8.0176e-03],\n","        [-1.0332e-01,  8.4782e-02, -9.5599e-02,  ..., -1.4293e-04,\n","          1.5712e-01, -1.6272e-01],\n","        [-6.0029e-02,  1.0859e-01, -1.3341e-01,  ..., -2.1058e-02,\n","          3.3074e-02, -1.2555e-01]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["#load\n","train_dst = datasets.CIFAR100('datasets2/', train=True, download=True, transform=ToTensor())\n","train_loader = DataLoader(train_dst, shuffle=True, batch_size=batch_size)\n","\n","test_dst = datasets.CIFAR100('datasets2/', train=False, download=True,  transform=ToTensor())\n","test_loader = DataLoader(test_dst, shuffle=True, batch_size=batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1MMuXqyzk2n","executionInfo":{"status":"ok","timestamp":1687889738437,"user_tz":420,"elapsed":2984,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}},"outputId":"75b98ebe-452e-4b40-81a6-692adb4168f9"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["#init - model init -> device\n","model = CifarCNN(num_classes = num_classes).to(device=device)"],"metadata":{"id":"F7w7yejwzk6a","executionInfo":{"status":"ok","timestamp":1687886036577,"user_tz":420,"elapsed":187,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["#loss+opt\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = optim.NAdam(model.parameters(), lr=lr)"],"metadata":{"id":"O4z7-qiQzk-a","executionInfo":{"status":"ok","timestamp":1687886037900,"user_tz":420,"elapsed":269,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["#train\n","num_epochs=5\n","for i in range(num_epochs):\n","  print(f'Epoch #{i+1}')\n","  for j, (data_batch_data, data_batch_targets) in enumerate(train_loader):\n","\n","    x = data_batch_data.to(device=device)\n","    y = data_batch_targets.to(device=device)\n","    scores = model(x)\n","    loss = criterion(scores, data_batch_targets)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    optimizer.step()"],"metadata":{"id":"W1CsisLKzry4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e8b70fa3-d901-42ed-ce42-229937db396f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch #1\n","Epoch #2\n","Epoch #3\n","Epoch #4\n"]}]},{"cell_type":"code","source":["def check_accuracy(loader,model ):\n","  num_correct = 0\n","  num_samples = 0\n","  if loader.dataset.train:\n","    print(\"training\")\n","  else:\n","    print(\"testing\")\n","  model.eval()\n","  for batch in loader:\n","    with torch.no_grad():\n","      x, y = batch\n","      x = x.to(device=device)\n","      y = y.to(device)\n","\n","      scores = model(x)\n","      _, predictions = scores.max(1)\n","      num_correct += (predictions == y).sum()\n","      num_samples += x.size(0)\n","  print(f'{float(num_correct)/float(num_samples)*100:.2f}')\n","  model.train()\n","\n","check_accuracy(train_loader, model)\n","check_accuracy(test_loader, model)"],"metadata":{"id":"69jWsVQK3G_U","executionInfo":{"status":"ok","timestamp":1687886281525,"user_tz":420,"elapsed":26527,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"74f4c059-70a0-4002-aa1e-cc1f48677ca7"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["training\n","16.57\n","testing\n","15.73\n"]}]}]}