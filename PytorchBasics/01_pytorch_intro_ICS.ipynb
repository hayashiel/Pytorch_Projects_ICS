{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":5384,"status":"ok","timestamp":1687711308181,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"olHRO3e6rWaq"},"outputs":[],"source":["#youtube.com/watch?v=2S1dgHpqCdk\u0026list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz\n","#Aladdin's Tutorial\n","import torch\n","import torch.nn as nn\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1687711308484,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"T2jPjynorm6A"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[1., 2., 3.],\n","         [4., 5., 6.]]], requires_grad=True)\n"]}],"source":["# basic tensor and gpu\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #check availability\n","data_here = [[1,2,3], [4,5,6]]\n","my_tensor = torch.tensor([data_here], dtype = torch.float32,\n","                         device= device, #if 0==0 else \"cuda\"\n","                         requires_grad=True) # autograd\n","# cuda or cpu\n","print(my_tensor)\n","# .dtype and .device"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1687711308485,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"jFizwBH3swQV"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[1., 2., 3.],\n","         [4., 5., 6.]]], requires_grad=True) has torch.float32 and  is on device \n"," cpu respectively.  The tensor has shape torch.Size([1, 2, 3]) and the option for autograd is True\n"]}],"source":["print(f'{my_tensor} has {my_tensor.dtype} and \\\n"," is on device \\n {my_tensor.device} respectively. \\\n"," The tensor has shape {my_tensor.shape} and the option for autograd is {my_tensor.requires_grad}')\n","# .dtype and .device respectively"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1687711308485,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"pzUhl2ghtm-c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0, 1, 2, 3, 4])\n","tensor([False,  True,  True,  True])\n","tensor([0, 1, 2, 3], dtype=torch.int16)\n","tensor([0, 1, 2, 3])\n"]}],"source":["x = torch.empty(size = (3,3)) # like np.random\n","x = torch.zeros((3,3)) #like np.zeros(tuple)\n","x = torch.rand((3,3)) #np.random - normal\n","x = torch.ones((3,3)) #like np.ones\n","x = torch.eye(5,5) # like np.eye\n","\n","#range-type  functions have start, end, and steps\n","x = torch.arange(start=0, end=5, step = 1) # like np arange and range *python\n","print(x)\n","x = torch.linspace(start=0.1, end=1, steps=10) #like np.linspace\n","#torch.empty has initializing functions ending with _, such as uniform_ and normal_\n","x = torch.empty(size=(6,9)).normal_(mean=0, std=1)\n","x = torch.empty(size=(6,9)).uniform_(0, 1)\n","\n","x = torch.diag(torch.ones(3)) # Create diagonal of ones, special - identity/eye\n","y = np.diag([[0,1,2], [3,4,5], [6,7,8]]) #extract diagonal\n","\n","#tensor type conversions - explicit\n","tensor = torch.arange(4)\n","print(tensor.bool())\n","print(tensor.short())\n","print(tensor.long())\n","#float double half\n","\n","# conversions np and torch\n","np_tensor = tensor.numpy()\n","tensor = torch.from_numpy(np_tensor)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1687711308485,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"7jKjj2BcrHzo"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([5, 7, 9])\n","tensor([5, 7, 9])\n","tensor([5, 7, 9])\n","tensor([1, 2, 3])\n","tensor([20, 35, 54])\n","tensor([1.2500, 1.4000, 1.5000])\n","tensor([1.2500, 1.4000, 1.5000])\n"]}],"source":["# Math and \u003c= operations\n","\n","#corresponding inplace operations by operation_ and python overloaded ie. torch.add(x, y, out=z) -\u003e x+y -\u003e x.add_\n","#subtracion\n","c = torch.empty(3) #placeholder with shape of output\n","x = torch.tensor([1,2,3])\n","y = torch.tensor([4,5,6])\n","print(x+y)\n","print(torch.add(x, y))\n","print(x.add_(y))\n","#Subtraction\n","print(torch.subtract(x,y))\n","#...\n","print(torch.multiply(x,y))\n","\n","#division\n","print(torch.divide(x,y))\n","print(torch.true_divide(x,y))\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687711308485,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"s4CifdgMsb3q"},"outputs":[],"source":["#little test\n","x = torch.tensor([1,2,3], dtype=torch.float32)\n","y = x*3+3"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687711308486,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"K7UVYrb9-rxW"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 6.,  9., 12.])\n"]}],"source":["print(y)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687711308486,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"LfI8X20v-tWN"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3])\n","torch.Size([1, 3])\n"]}],"source":["n = 3\n","\n","w = torch.rand((1, n ))\n","b = torch.rand((1, n))\n","print(x.size())\n","print((x*w+b).size())"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1687711308793,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"S9ylTVEk_XfK"},"outputs":[],"source":["def loss_function(x, y_pred, y):\n","  print(x.shape)\n","  J = torch.sum(torch.subtract(y_pred, y) ** 2)/n\n","  return (J*x, J)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1687711309051,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"XNbfmmGfAMKv"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n","torch.Size([3])\n"]}],"source":["epsilon = 1e-4\n","for i in range(1000):\n","  y_pred = x * w + b\n","  dw, db = loss_function(x, y_pred, y)\n","  w = torch.subtract(epsilon*dw, w)\n","  b = torch.subtract(epsilon*db, b)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1687711309052,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"_CULQeQVBFBO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":264,"status":"ok","timestamp":1687711309314,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"ItnF9Mp7AoAS"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 6., 18., 36.])\n","tensor(60.)\n","tensor([[[4.7743, 4.9023, 6.8897,  ..., 5.1805, 5.0233, 3.6928],\n","         [4.9822, 3.7150, 5.5492,  ..., 4.2282, 4.8526, 3.8588],\n","         [4.1996, 3.9166, 5.7912,  ..., 3.8364, 3.4248, 2.7072],\n","         ...,\n","         [7.4558, 6.2413, 8.4410,  ..., 6.3215, 6.0238, 4.0327],\n","         [5.1266, 5.2728, 5.2049,  ..., 4.7469, 5.1193, 3.3715],\n","         [6.7506, 5.4785, 6.8038,  ..., 6.0181, 5.6936, 4.6214]],\n","\n","        [[6.8539, 6.2841, 5.9942,  ..., 5.9012, 6.8111, 5.7208],\n","         [5.5667, 5.0442, 5.4811,  ..., 5.7017, 6.3862, 5.8638],\n","         [5.0092, 5.5013, 4.2644,  ..., 4.8522, 5.6181, 4.8725],\n","         ...,\n","         [4.4146, 4.7781, 3.6597,  ..., 4.4554, 4.9067, 4.4331],\n","         [4.9785, 4.9584, 4.9365,  ..., 4.7995, 5.7719, 4.4821],\n","         [5.8431, 5.2544, 5.5171,  ..., 5.9240, 6.3597, 5.1362]],\n","\n","        [[4.5655, 3.3265, 4.0628,  ..., 4.1559, 4.5639, 3.9459],\n","         [4.8227, 4.4629, 3.6379,  ..., 3.7589, 4.5820, 4.2322],\n","         [5.3811, 3.4526, 4.9151,  ..., 4.3873, 5.2307, 4.9322],\n","         ...,\n","         [4.2344, 3.5239, 4.1121,  ..., 3.6013, 4.2299, 3.2860],\n","         [3.9985, 3.6580, 3.9640,  ..., 4.1244, 4.8413, 3.7650],\n","         [4.8322, 4.1397, 4.4443,  ..., 3.7420, 4.5813, 4.5338]],\n","\n","        ...,\n","\n","        [[5.6559, 7.9811, 6.1340,  ..., 5.6273, 5.4253, 8.0842],\n","         [4.7305, 5.2128, 4.2515,  ..., 5.7482, 3.7695, 5.5617],\n","         [3.7490, 5.4999, 3.1867,  ..., 4.4845, 2.9819, 5.2573],\n","         ...,\n","         [3.7063, 5.9289, 4.0679,  ..., 4.8454, 4.2130, 5.3799],\n","         [3.1252, 3.9103, 3.0075,  ..., 2.9553, 3.3299, 4.2917],\n","         [4.5855, 6.3640, 5.8281,  ..., 5.8667, 4.4846, 6.3887]],\n","\n","        [[4.7609, 3.7342, 5.2882,  ..., 4.5423, 4.4902, 4.3531],\n","         [4.5161, 4.8941, 5.8637,  ..., 4.9403, 4.6055, 5.0079],\n","         [4.9556, 4.9839, 5.8262,  ..., 4.8968, 5.4296, 4.6378],\n","         ...,\n","         [5.8979, 5.4476, 6.3907,  ..., 5.6395, 5.9921, 5.5448],\n","         [4.8006, 4.6981, 5.1258,  ..., 5.1679, 5.1444, 4.4440],\n","         [4.9397, 4.4171, 5.1246,  ..., 5.8703, 5.3457, 5.6885]],\n","\n","        [[3.7964, 5.3887, 3.6694,  ..., 4.1377, 4.3651, 4.3674],\n","         [4.0381, 3.9069, 3.6654,  ..., 4.6300, 3.9457, 5.4941],\n","         [5.9932, 4.5827, 4.5202,  ..., 6.0467, 5.0908, 5.8650],\n","         ...,\n","         [6.0373, 6.4883, 5.7079,  ..., 7.1446, 5.4568, 7.0914],\n","         [5.5462, 6.1672, 5.2513,  ..., 6.1763, 4.9119, 6.4575],\n","         [5.1118, 5.8410, 5.2555,  ..., 5.2846, 4.8384, 6.2909]]])\n"]}],"source":["\n","\n","# versus element mult\n","z = x*y\n","print(z)\n","\n","# dot product sum(element mult)\n","z = torch.dot(x, y)\n","print(z)\n","\n","#mm\n","x1 = torch.rand((3,4))\n","x2 = torch.rand((4, 6))\n","x3 = torch.mm(x1, x2) # matrix mult\n","x3 = x1.mm(x2)\n","\n","# batch mm\n","# add extra dimension for batch - use bmm instead of mm\n","batch = 32\n","n = 10\n","m = 20\n","p = 30\n","tensor1 = torch.rand(batch, n, m) # same thing, m must match for matrix mult\n","tensor2 = torch.rand(batch, m, p)\n","out_bmm = torch.bmm(tensor1, tensor2)\n","print(out_bmm)\n","\n","#broadcasting in pytorch, numpy, tf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1687711309315,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"MdAQxyTFAzCK"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1.3724, 1.7565, 1.1676, 1.1139, 0.8417],\n","        [2.4375, 2.8066, 1.8899, 2.1555, 1.4540],\n","        [3.7882, 4.7020, 3.1175, 3.4549, 2.0689],\n","        [2.2655, 2.6990, 1.7720, 1.9178, 1.2984],\n","        [1.9440, 2.2404, 1.6193, 1.6873, 1.1709]])\n"]}],"source":["#Matrix exp\n","matrix_exp = torch.rand(5,5)\n","print(matrix_exp.matrix_power(3))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1687711624605,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"WBwGEUFWbvwp"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([False, False, False])\n"]}],"source":["# useful math functions\n","#sum, max, dim, take x and dim= on dimension specified, argmax/min return index\n","#abs input\n","mean_x  = torch.mean(x.float(), dim=0) # requires float\n","\n","#comparison\n","z = torch.eq(x,y)\n","print(z)\n","\n","sorted_y, indices = torch.sort(y, dim=0, descending=False) # sort on dim, descending False -\u003e ascend\n","z = torch.clamp(x, min=0, max=10) # set less than or greater than to ceil/floor\n","x = torch\n","\n","# boolean operations\n","x = torch.tensor([1,0,0,1,1], dtype=torch.bool)\n","z = torch.any(z)# multiple or st\n","z = torch.all(z) # and multiple\n","\n","#for functions, also same methods - input\n","#ie. torch.max(x, dim=0) -\u003e x.max(dim=0)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1687711645242,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"A-M2c0Svc8Z6"},"outputs":[],"source":["gradient = torch.clamp(x, max=1) # g clip"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1687712116745,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"hzjI9Ocpd2on"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0, 1, 9])\n","tensor(2)\n"]}],"source":["#indices operations\n","#assignment and access same as python\n","#.shape -\u003e shape\n","#can use list of indices -\u003e x[indices]\n","\n","#boolean operations (advanced)\n","my_list = torch.arange(10)\n","print(my_list[(my_list \u003c 2) | (my_list\u003e8)])\n","#x.remainder(2) -\u003e returns quotient of x/2 numbers - even\n","\n","print(torch.where(z\u003e5, z, z*2)) # compare to tf.where\n","# condition, true, false\n","#.unique() gets unique\n","#.ndimension() return dim\n","#.numel() #number ofelements"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1687712549587,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"uiILAKmbf7oQ"},"outputs":[],"source":["d = torch.tensor([[1,2,3], [4,5,6]], dtype=torch.float32)\n","e = torch.tensor([[4,5], [6,7], [8,9]], dtype=torch.float32)\n","f = d.mm(e)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1687712575723,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"ioIYCcIRgdMs"},"outputs":[{"name":"stdout","output_type":"stream","text":["4\n","2\n","tensor([ 40.,  46.,  94., 109.])\n"]}],"source":["print(f.numel())\n","print(f.ndimension())\n","print(f.unique())"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1687712778036,"user":{"displayName":"Ethan1312","userId":"05933093219846915150"},"user_tz":420},"id":"T_JDw93Aglhc"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0, 1, 2],\n","        [3, 4, 5],\n","        [6, 7, 8]])\n","tensor([[0, 3, 6],\n","        [1, 4, 7],\n","        [2, 5, 8]])\n","tensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-18-a6d99c804fe5\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 26\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# swap dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#ie. matrix of 25, 1, 2 -\u003e 25, 2, 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 26\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# for dimensions, put in indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 1 is not equal to len(dims) = 3"]}],"source":["#reshaping\n","x = torch.arange(9)\n","#view and reshape similar, view - contiguous tensor, reshape doesn't - perform loss\n","x_3x3 = x.view(3,3)\n","x_3x3 = x.reshape(3,3)\n","print(x_3x3)\n","\n","#transpose - .t() - not contiguous\n","y = x_3x3.t()\n","print(y)\n","#print(y.view()) # doesn't work\n","print(y.contiguous().view(9)) # make contiguous\n","\n","#.cat(shape=)\n","#flatten to 1d\n","x.reshape(-1)\n","#flatten on a dim / custom dim\n","#batch, 2, 5, -\u003e batch, -1 -\u003e batch, 10\n","\n","# inverse of flatten\n","x.unsqueeze(0) # dimension index to expand on\n","\n","\n","# swap dim\n","#ie. matrix of 25, 1, 2 -\u003e 25, 2, 1\n","z = x.permute(0, 2, 1) # for dimensions, put in indices\n"]},{"cell_type":"markdown","metadata":{"id":"RQLwMkEeg6BB"},"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPTrYATgJNBMVlwy8kvAS/E","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
